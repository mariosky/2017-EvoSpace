\section{Introduction}
% Main Ideas:
%Why Paralel
A large body of work exists in EA parallelization, using multiple CPU cores, multiple 
nodes and GPUs \cite{cantu2000efficient,hofmann2013performance}.
However, asynchronous EAs have started to become common only recently, 
in an effort to exploit computing resources available through popular Internet technologies
through popular Internet technologies
%Pool Based
In this work, we are interested in EAs that follow a
pool-based approach, where the search process is conducted by a
collection of heterogeneous processes that collaborate using
a shared repository or population pool. We will refer to such
algorithms as Pool-based EAs or PEAs, and highlight the fact that such
systems are intrinsically parallel, distributed and asynchronous.

The particular PEA platform immplemented in this paper is based on  
the EvoSpace framework \cite{GValdez2015} in which distributed nodes 
(or workers) asynchronously interact  with the pool by taking a sample 
of the population and performing a local evolutionary search on 
the population sample, then returning to the pool the newly evolved solutions. 
Pool-EAs differ from the closely related island model, mainly with regards to 
the responsibilities that are assigned to the server. In the island model 
the server is usually responsible for the interaction and synchronization 
of all the populations, while in a Pool-EA the server only receives stateless
requests from isolated participants or clients. In this way, Pool-EAs 
are capable of an ad-hoc collaboration of computing resources. 

% Evaluate in EvoSpace
The software system presented here is a new immplementation 

The remainder of the paper proceeds as follows.  Section \ref{sec:work} 
reviews related work. Afterwards, Section \ref{sec:evo} briefly describes the
proposed EvoSpace cloud implementation, the experimental work is presented in 
Section \ref{sec:experiments}. Finally, a summary and concluding remarks are given in
Section \ref{sec:conclusions}.


\section{Related Work}
\label{sec:work}
There are two important practical issues faced by many EA systems, namely the size of the parameter 
space and the high computational cost when it is compared with mathematical programming or numerical techniques.
Concerning the latter, one approach to mitigate this issue is to use parallel or 
distributed implementations \cite{cantu-paz:migration-policies,duda2013gpu}.
For instance, Fern\'andez et al. \cite{nc} % articulo Paco, Gustavo y Leo publucado en Natural Computing}
uses the well-known Berkeley Open Infrastructure for Network Computing (BOINC) to distribute EA runs across a
heterogeneous network of volunteer computers using virtual machines. Another recent example is 
found in the FlexGP system developed by Sherry et al. \cite{sherry2012flex}. FlexGP is probably the first large scale GP system 
that runs on the cloud, using an Island model approach and implemented over Amazon EC2 with a 
socket-based client-server architecture.

Another approach to distributed EAs is the so called pool-based architecture. In general, a 
pool-based system employs a central repository (real or virtual) where the evolving population is stored.
Distributed clients interact with the pool, performing some or all of the basic EA processes 
(selection, genetic operators, survival). A representative work of this approach 
is that by Merelo et al. \cite{agajaj} implementing a JavaScript based PEA that distributes 
the evolutionary process over the web, providing the added advantage of not requiring the 
installation of additional software in each computing node.  Other similar cloud-based solutions 
are based on a global queue of tasks and a Map-Reduce implementation which normally handles failures 
by the re-execution of  tasks \cite{fazenda2012,di2013towards,FlexGP}. Using the BOINC 
volunteer platform  Smaoui et al. \cite{FekiNG09} uses work units that consist of a fitness 
evaluation task and multiple replicas  were produced and sent to different clients.

While using a distributed framework can ease the computational cost, it can also exacerbate the first issue mentioned above;
i.e., it increases the size of the algorithm parameter space, which makes parameter tuning a more difficult task.
The issue of optimal parametrization of EAs is a widely studied subject \cite{de2007parameter}, 
with many approaches in literature. For instance, one of the most successful approaches 
is the F-Racing and iterative F-Racing techniques \cite{lopez2011irace}. 
However, while such algorithms can find high performance parametrizations, 
they require additional computational effort which can be too expensive in some applications
(even if they are more efficient than an exhaustive search).



\section{Conclusions and Further Work}
\label{sec:conclusions}

% To be written

Future lines of work will focus on using other EA or meta-heuristic techniques, 
such as genetic programming or particle swarm optimization for having 
workers that are heterogeneous in more than one sense. RPSS could be
used in those cases where each algorithm has different sets of
parameters, but also to randomly select the technique used in each
node. Another interesting line of work is the dynamic adaptation of
parameters by measuring the diversity of each worker or returned
sample. This could be specially useful in cases where the random
parametrization technique seems to achieve bad results. 

\begin{acks}
This work has been supported in part by:  Ministerio espa\~{n}ol de
Econom\'{\i}a y Competitividad under project TIN2014-56494-C4-3-P
(UGR-EPHEMECH).
\end{acks}
